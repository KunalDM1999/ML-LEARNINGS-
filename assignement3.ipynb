{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWtaZSrr7HqrphAvPi/5oM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunalDM1999/ML-LEARNINGS-/blob/main/assignement3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/DataPreprocessingGraded_dataset.csv')\n",
        "\n",
        "# Replace '?' with NaN\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Define feature indices\n",
        "numeric_impute_features = [0, 1]\n",
        "numeric_scale_features = [0, 1, 2, 3]\n",
        "categorical_features = [4]\n",
        "\n",
        "# Select only numeric columns for imputer and scaler\n",
        "numeric_columns = df.columns[:4]  # Assuming first four columns are numeric\n",
        "categorical_columns = df.columns[4:5]  # Assuming the fifth column is categorical\n",
        "\n",
        "# Define transformers\n",
        "numeric_imputer = SimpleImputer(strategy='mean')\n",
        "scaler = StandardScaler()\n",
        "encoder = OrdinalEncoder()\n",
        "\n",
        "# Define ColumnTransformer for numeric features with imputation and scaling\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', numeric_imputer),\n",
        "    ('scaler', scaler)\n",
        "])\n",
        "\n",
        "# Define ColumnTransformer for categorical features with encoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('encoder', encoder)\n",
        "])\n",
        "\n",
        "# Combine transformers into a preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns),\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the full pipeline including VarianceThreshold\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('var_threshold', VarianceThreshold(threshold=0.1))\n",
        "])\n",
        "\n",
        "# Apply the pipeline to the dataframe\n",
        "processed_data = pipeline.fit_transform(df)\n",
        "\n",
        "# Display the resulting feature matrix\n",
        "print(\"Number of features after pipeline:\", processed_data.shape[1])\n",
        "print(\"Processed feature matrix:\")\n",
        "print(processed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNI9OtCVeBZx",
        "outputId": "88391e27-45b9-4530-aaa4-d81a250ebe6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features after pipeline: 4\n",
            "Processed feature matrix:\n",
            "[[-9.38169390e-01  7.70986653e+00  7.62334626e+00  2.61563344e+00]\n",
            " [-1.18627754e+00  1.30454949e+00  1.28273826e+00 -2.57880900e-01]\n",
            " [ 0.00000000e+00 -1.53758496e-16  1.79684161e+00  2.94705348e-02]\n",
            " ...\n",
            " [ 1.66696622e+00 -4.26617275e-01 -4.30939574e-01  1.13782607e+00]\n",
            " [ 3.65183145e+00 -7.72850628e-01 -7.73675141e-01  1.93671355e-01]\n",
            " [ 7.74561598e+00 -7.72850628e-01 -7.73675141e-01  1.54832812e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xaIOuaiEp_Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.feature_selection import VarianceThreshold, RFE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "\n",
        "# Separate the features and the target variable\n",
        "X = df.drop(columns='Target')  # Replace 'target' with the actual target column name\n",
        "y = df['Target']  # Replace 'target' with the actual target column name\n",
        "\n",
        "# Replace '?' with NaN\n",
        "X.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Define feature indices\n",
        "numeric_impute_features = [0, 1]\n",
        "numeric_scale_features = [0, 1, 2, 3]\n",
        "categorical_features = [4]\n",
        "\n",
        "# Define columns\n",
        "numeric_columns = X.columns[:4]  # Assuming first four columns are numeric\n",
        "categorical_columns = X.columns[4:5]  # Assuming the fifth column is categorical\n",
        "\n",
        "# Define transformers\n",
        "numeric_imputer = SimpleImputer(strategy='mean')\n",
        "scaler = StandardScaler()\n",
        "encoder = OrdinalEncoder()\n",
        "\n",
        "# Define ColumnTransformer for numeric features with imputation and scaling\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', numeric_imputer),\n",
        "    ('scaler', scaler)\n",
        "])\n",
        "\n",
        "# Define ColumnTransformer for categorical features with encoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('encoder', encoder)\n",
        "])\n",
        "\n",
        "# Combine transformers into a preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns),\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the full pipeline including VarianceThreshold\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('var_threshold', VarianceThreshold(threshold=0.1))\n",
        "])\n",
        "\n",
        "# Apply the pipeline to the features\n",
        "X_processed = pipeline.fit_transform(X)\n",
        "\n",
        "# Encode the target variable\n",
        "target_encoder = OrdinalEncoder()\n",
        "y_encoded = target_encoder.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Define the LogisticRegression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define RFE with LogisticRegression as the estimator and 2 features to select\n",
        "rfe = RFE(estimator=model, n_features_to_select=2)\n",
        "\n",
        "# Fit RFE\n",
        "rfe.fit(X_processed, y_encoded)\n",
        "\n",
        "# Get the selected feature indices\n",
        "selected_features = rfe.support_\n",
        "selected_feature_indices = np.where(selected_features)[0]\n",
        "\n",
        "# Display the selected feature indices and their names\n",
        "print(\"Selected feature indices:\", selected_feature_indices)\n",
        "print(\"Selected feature names:\", X.columns[selected_feature_indices])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qELtH0TgTaR",
        "outputId": "d592c3b8-885e-4022-d0f8-45ea9ef6826b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected feature indices: [0 2]\n",
            "Selected feature names: Index(['V1', 'V3'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.feature_selection import VarianceThreshold, SequentialFeatureSelector\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Separate the features and the target variable\n",
        "X = df.drop(columns='Target')  # Replace 'target' with the actual target column name\n",
        "y = df['Target']  # Replace 'target' with the actual target column name\n",
        "\n",
        "# Replace '?' with NaN\n",
        "X.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Define feature indices\n",
        "numeric_impute_features = [0, 1]\n",
        "numeric_scale_features = [0, 1, 2, 3]\n",
        "categorical_features = [4]\n",
        "\n",
        "# Define columns\n",
        "numeric_columns = X.columns[:4]  # Assuming first four columns are numeric\n",
        "categorical_columns = X.columns[4:5]  # Assuming the fifth column is categorical\n",
        "\n",
        "# Define transformers\n",
        "numeric_imputer = SimpleImputer(strategy='mean')\n",
        "scaler = StandardScaler()\n",
        "encoder = OrdinalEncoder()\n",
        "\n",
        "# Define ColumnTransformer for numeric features with imputation and scaling\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', numeric_imputer),\n",
        "    ('scaler', scaler)\n",
        "])\n",
        "\n",
        "# Define ColumnTransformer for categorical features with encoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('encoder', encoder)\n",
        "])\n",
        "\n",
        "# Combine transformers into a preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns),\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the full pipeline including VarianceThreshold\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('var_threshold', VarianceThreshold(threshold=0.1))\n",
        "])\n",
        "\n",
        "# Apply the pipeline to the features\n",
        "X_processed = pipeline.fit_transform(X)\n",
        "\n",
        "# Encode the target variable\n",
        "target_encoder = OrdinalEncoder()\n",
        "y_encoded = target_encoder.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Define the LogisticRegression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define SFS with LogisticRegression as the estimator and forward selection\n",
        "sfs = SequentialFeatureSelector(model, n_features_to_select=2, direction='forward')\n",
        "\n",
        "# Fit SFS\n",
        "sfs.fit(X_processed, y_encoded)\n",
        "\n",
        "# Get the selected feature indices\n",
        "selected_features = sfs.get_support(indices=True)\n",
        "\n",
        "# Display the selected feature indices and their names\n",
        "print(\"Selected feature indices:\", selected_features)\n",
        "print(\"Selected feature names:\", X.columns[selected_features])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmxXEivjhaat",
        "outputId": "a790eeed-0aaf-4f75-d5cd-b8e56fd97dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected feature indices: [1 3]\n",
            "Selected feature names: Index(['V2', 'V4'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.feature_selection import VarianceThreshold, SequentialFeatureSelector\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Separate the features and the target variable\n",
        "X = df.drop(columns='Target')  # Replace 'target' with the actual target column name\n",
        "y = df['Target']  # Replace 'target' with the actual target column name\n",
        "\n",
        "# Replace '?' with NaN\n",
        "X.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Define feature indices\n",
        "numeric_impute_features = [0, 1]\n",
        "numeric_scale_features = [0, 1, 2, 3]\n",
        "categorical_features = [4]\n",
        "\n",
        "# Define columns\n",
        "numeric_columns = X.columns[:4]  # Assuming first four columns are numeric\n",
        "categorical_columns = X.columns[4:5]  # Assuming the fifth column is categorical\n",
        "\n",
        "# Define transformers\n",
        "numeric_imputer = SimpleImputer(strategy='mean')\n",
        "scaler = StandardScaler()\n",
        "encoder = OrdinalEncoder()\n",
        "\n",
        "# Define ColumnTransformer for numeric features with imputation and scaling\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', numeric_imputer),\n",
        "    ('scaler', scaler)\n",
        "])\n",
        "\n",
        "# Define ColumnTransformer for categorical features with encoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('encoder', encoder)\n",
        "])\n",
        "\n",
        "# Combine transformers into a preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns),\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the full pipeline including VarianceThreshold\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('var_threshold', VarianceThreshold(threshold=0.1))\n",
        "])\n",
        "\n",
        "# Apply the pipeline to the features\n",
        "X_processed = pipeline.fit_transform(X)\n",
        "\n",
        "# Encode the target variable\n",
        "target_encoder = OrdinalEncoder()\n",
        "y_encoded = target_encoder.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Define the LogisticRegression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define SFS with LogisticRegression as the estimator and forward selection\n",
        "sfs = SequentialFeatureSelector(model, n_features_to_select=2, direction='backward')\n",
        "\n",
        "# Fit SFS\n",
        "sfs.fit(X_processed, y_encoded)\n",
        "\n",
        "# Get the selected feature indices\n",
        "selected_features = sfs.get_support(indices=True)\n",
        "\n",
        "# Display the selected feature indices and their names\n",
        "print(\"Selected feature indices:\", selected_features)\n",
        "print(\"Selected feature names:\", X.columns[selected_features])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7AezXLMiUfU",
        "outputId": "de24748c-4ceb-4902-8549-fa4290f72160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected feature indices: [2 3]\n",
            "Selected feature names: Index(['V3', 'V4'], dtype='object')\n"
          ]
        }
      ]
    }
  ]
}